"""
Напишите программу, которая перемножает две матрицы.

На вход программе подаются два натуральных числа n и m — количество строк и столбцов в первой матрице, 
затем элементы первой матрицы, затем пустая строка.  

Далее следуют числа m и k — количество строк и столбцов второй матрицы затем элементы второй матрицы.

Программа должна вывести результирующую матрицу, разделяя элементы символом пробела.

# Ввод:
2 2
1 2
3 2

2 2
3 2
1 1

# Вывод
5 4
11 8
"""

# Решение

# Принимаем параметры первой матрицы, заполняем ее
n, m = map(int, input().split())
matrix_1 = [[int(j) for j in input().split()] for i in range(n)]

# Пропускаем пустую строку
input()

# Принимаем параметры второй матрицы, заполняем ее
m, k = map(int, input().split())
matrix_2 = [[int(j) for j in input().split()] for i in range(m)]

# Подготавливаем результирующую матрицу, которая по сути является общей частью для первых двух матриц.
matrix_result = [[0]*k for _ in range(n)]

# Первые два цикла i и j проходятся по элементам 3 матрицы.
for i in range(k):
    for j in range(n):
        # Третий цикл связан с количеством сложений элементов 1 и 2 матриц,
        # нужных чтобы в итоге получить "произведение" для каждого элемента в 3 матрице.
        for k in range(m):
            matrix_result[i][j] += matrix_1[i][k]*matrix_2[k][j]
    print(*matrix_result[i])
